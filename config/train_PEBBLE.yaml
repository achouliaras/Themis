defaults:
    - _self_
    - sac
    
# this needs to be specified manually
experiment: PEBBLE

# reward learning
segment: 50
activation: tanh
num_seed_steps: 1000 #1000
num_unsup_steps: 5000 #5000
num_interact: 5000
reward_lr: 0.0003
reward_batch: 128
reward_update: 200
feed_type: 0
reset_update: 100
topK: 5
ensemble_size: 3
max_feedback: 1400
large_batch: 10
label_margin: 0.0
teacher_beta: -1
teacher_gamma: 1
teacher_eps_mistake: 0
teacher_eps_skip: 0
teacher_eps_equal: 0

# scheduling
reward_schedule: 0

num_train_steps: 1e6
replay_buffer_capacity: ${num_train_steps}

# evaluation config
eval_frequency: 5 #10000
num_eval_episodes: 20
device: cpu

# logger
log_frequency: 10000
log_save_tb: true

# video recorder
save_video: false

# setups
seed: 1

# Environment
domain: Control
env: Ant-v4
render_mode: None
gradient_update: 1

#Task Settings
obs_type: states # [states, pixels]
frame_stack: 4 # only works if obs_type=pixels
frameskip:
action_repeat: 1 # set to 2 for pixels
mode :
difficulty :
repeat_action_probability:
full_action_space:

# Snapshot
snapshots: [100000, 500000, 1000000, 2000000]
snapshot_dir: models/${obs_type}/${env}/sac/
