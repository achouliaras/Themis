Each video clip is organised as follows:
On the left side are the clips for segment 1.
On the right side are the clips of segment 2.
On the top are the clips rendered from the environment.
On the bottom, the clips contain the saliency maps explanation overlayed on top of the environment in grayscale. The lower resolution is due to rescaliling done when giving the input to the RL model.
In the training phase, the users vew multiple clips and for each, they are tasked to select between the left segment and the right segment.
There is also a clip of the scenario the bot follows to simulate real user interaction with our crowdsourcing platform.